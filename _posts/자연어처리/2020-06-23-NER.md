---
title:  "개체명인식(NER)"
excerpt: "Named Entity Recognition"
header:
  teaser: /assets/images/nlp/input_representation.jpg

categories:
  - NLP
tags:
  - NER
last_modified_at: 2020-06-23T11:30
---


개체명인식(NER): Named Entity Recognition    

|	<center>NER 모델 2part</center>	| 
| :------------------------------------	| 
| 1. Embedding (BERT)			|
| 2. 개체명인식 (BI-LSTM +CRF)		|


### 개체명인식 문제 (N to N, Many to Many)  
일반적인 NLP문제 (N to 1, Many to One) vs. 개체명인식 문제 (N to N, Many to Many)  
1. 입력이 문장일때, 문장의 <span style="color:red">단어들 모두</span> Entity나 POS를 추정하는 결과값을 내줘야 한다.  
2. 모든 단어에 대한 hidden vector 에 softmax를 이용하여 class를 구분하고 실제 label들과 비교하여 loss를 구한다.  

![]({{ site.url }}{{ site.baseurl }}/assets/images/nlp/ner.jpg   ){: .align-center}


### 1. NER을 위한 Embedding      
![]({{ site.url }}{{ site.baseurl }}/assets/images/nlp/ner_embedding.png   ){: .align-center}

주로 <span style="color:red">word단위</span> 임베딩 + <span style="color:red">char단위</span> 임베딩 + <span style="color:red">부정보</span>(handcrafted word features)를 사용, 최근 BERT나 ELMo도 사용  


### 2. NER의 모델구조  
NER의 구조는 아래와 같이 발전해 왔다.  
![]({{ site.url }}{{ site.baseurl }}/assets/images/nlp/ner_structure.jpg   ){: .align-center}


### 3. CRF를 이용하여 성능 끌어올리기  
RNN계열로 매 입력 token마다 label을 예측하지만, 이는 입력 단어간의 관계만 파악하고, <span style="color:red">label들 간의 관계</span>는 파악하지 않는다.  
그래서, 기존의 양방향 RNN계열 모델에 CRF(Conditional Random Field)층을 추가적으로 쌓는다.  
CRF는 label들 간의 관계를 파악하여 sequence labeling에서 가장 높은 점수를 가지는 정답 label을 출력한다.  
연달은 token에 <span style="color:red">같은 label이 있는 경우</span> 시작 label 앞에 'B'를, 끝 label앞에 'E'를, 중간 label들에는 'I'를 추가한다.  
지정한 label에 해당되지 않는 경우는 'O', 한 token으로 이루어진 label은 'S'를 추가한다.  
이러한 <span style="color:red">label들 간의 규칙을 학습</span>하여 적용하는 층이 CRF층 이다.  

![]({{ site.url }}{{ site.baseurl }}/assets/images/nlp/BiLSTM-CRF.png   ){: .align-center}



*[출처] <https://keep-steady.tistory.com/20>