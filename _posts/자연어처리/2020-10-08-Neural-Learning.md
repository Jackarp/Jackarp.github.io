---
title:  "신경망 학습"
excerpt: "신경망 학습"
header:
  teaser: /assets/images/nlp/sigmoid.png

categories:
  - NLP
tags:
  - 손실 함수
  - loss function
  - 오버피팅
last_modified_at: 2020-10-08T16:00
---

##### 신경망 학습         
학습이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득함을 뜻함   

손실함수: 신경망이 학습할 수 있도록 해주는 지표  

손실함수의 결과값을 가장 작게 만드는 가중치 매개변수를 찾는 것이 학습의 목표(함수의 기울기 활용 경사법)       

오버피팅: 한 데이터셋에만 지나치게 최적화된 상태   

| <center>손실 함수</center>	|
| :--------------------	|
| 1. 평균제곱오차		|
| 2. 교차 엔트로피 오차	|

미니배치: 데이터 일부를 추려 전체의 '근사치'로 이용(미니배치 학습)  
모든 훈련데이터를 대상으로 손실 함수값을 구해야 되기 때문에 불가능(즉 훈련데이터가 100개 있으면, 그로부터 계산한 100개의 손실 함수 값들의 합을 지표로)->미니배치 학습
